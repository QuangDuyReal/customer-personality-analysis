{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2549419,"sourceType":"datasetVersion","datasetId":1546318}],"dockerImageVersionId":30303,"isInternetEnabled":false,"language":"r","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"The interest of this project is attempting to segment customers on the basis of their spending on different types of products (wine, fruits, meat, etc.). Regression methods will be used to determine the significant features in each segment, which will help us determine the group at which marketing campaigns for a specific type of product should be targeted.","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:44:24.100359Z","iopub.execute_input":"2022-12-01T09:44:24.102535Z","iopub.status.idle":"2022-12-01T09:44:24.209969Z"}}},{"cell_type":"code","source":"# System setup\nrm(list = ls())\nknitr::opts_chunk$set(echo = TRUE, cache=TRUE)\nif(!require('pacman')) {\n  install.packages('pacman')\n}\npacman::p_load(caret,dplyr,rsample, recipes, ggplot2, nnet, gam, tidyverse, \n               GGally, corrplot, FNN, gmodels, earth, kernlab, vip, DiagrammeR,rsvg,\n               rpart,rpart.plot,ranger, h2o, gbm, xgboost, e1071, party, partykit, Metrics)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:45:28.706883Z","iopub.execute_input":"2022-12-01T09:45:28.76249Z","iopub.status.idle":"2022-12-01T09:45:35.301925Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 1. Exploratory Data Analysis and Data Mutation\nLoad the data.","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:49:28.635348Z","iopub.execute_input":"2022-12-01T09:49:28.637196Z","iopub.status.idle":"2022-12-01T09:49:28.648903Z"}}},{"cell_type":"code","source":"customers <- read.csv(\"/kaggle/input/customer-personality-analysis/marketing_campaign.csv\", sep = \"\\t\")\ncustomers <- customers[, -1] # remove ID","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:50:19.496116Z","iopub.execute_input":"2022-12-01T09:50:19.498638Z","iopub.status.idle":"2022-12-01T09:50:19.561825Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Data mutation","metadata":{}},{"cell_type":"code","source":"customers <- customers %>% \n  mutate(\n    # 2014 is used as the \"current year\" to calculate age \n    # to match the date this dataset is produced\n    Age = 2014 - Year_Birth, \n    HaveKids = ifelse(Kidhome + Teenhome > 0, 1, 0),\n    # using the last date in \"Dt_Customer\" to calculate how long the customer \n    # has enrolled as a customer in this supermarket\n    DaysCustomer = as.numeric(max(as.Date(Dt_Customer,\"%d-%m-%Y\"))\n                                     - as.Date(Dt_Customer,\"%d-%m-%Y\")), \n    Married= ifelse(Marital_Status==\"Married\"|Marital_Status==\"Together\", 1, 0),\n    Graduated= ifelse(Education == \"2n Cycle\" | Education ==\"Basic\", 0, 1)) %>% \n  select(-c(Year_Birth, Kidhome, Teenhome, Dt_Customer, Marital_Status))\n\nstr(customers) # inspect the structure of the data","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:53:32.727692Z","iopub.execute_input":"2022-12-01T09:53:32.72952Z","iopub.status.idle":"2022-12-01T09:53:32.848446Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Data Preprocessing\n\n## 2.1 Checking for missing value","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:53:45.646607Z","iopub.execute_input":"2022-12-01T09:53:45.653189Z","iopub.status.idle":"2022-12-01T09:53:45.677827Z"}}},{"cell_type":"code","source":"sum(is.na(customers))\ncustomers %>% \n  is.na() %>%\n  reshape2::melt() %>%\n  ggplot(aes(Var2, Var1, fill=value)) + \n    geom_raster() + \n    coord_flip() +\n    scale_y_continuous(NULL, expand = c(0, 0)) +\n    scale_fill_grey(name = \"\", \n                    labels = c(\"Present\", \n                               \"Missing\")) +\n    xlab(\"Observation\") +\n    theme(axis.text.y  = element_text(size = 4))","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:54:12.216227Z","iopub.execute_input":"2022-12-01T09:54:12.219117Z","iopub.status.idle":"2022-12-01T09:54:13.759021Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"There are 24 missing value and they are all in `Income`.","metadata":{}},{"cell_type":"markdown","source":"## 2.2 Outlier detection for people attributes","metadata":{}},{"cell_type":"code","source":"par(mfrow=c(1, 2))\ninvisible(lapply(c(2,24), function(i) boxplot(customers[, i], xlab = colnames(customers[i]))))","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:54:53.978489Z","iopub.execute_input":"2022-12-01T09:54:53.984077Z","iopub.status.idle":"2022-12-01T09:54:54.109527Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"There are 3 outliers in `Age` and 1 outlier in `Income`. Remove these for further analysis.","metadata":{}},{"cell_type":"code","source":"# removing customers whose age is greater than 100\ncustomers <- customers[-which(customers$Age>100),]\n# removing customer with highest income\ncustomers <- customers[-which.max(customers$Income),]","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:55:37.282357Z","iopub.execute_input":"2022-12-01T09:55:37.284866Z","iopub.status.idle":"2022-12-01T09:55:37.311116Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Checking the boxplots after removing the outliers.","metadata":{}},{"cell_type":"code","source":"par(mfrow=c(1, 2))\ninvisible(lapply(c(2,24), function(i) boxplot(customers[, i], xlab = colnames(customers[i]))))","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:55:59.491569Z","iopub.execute_input":"2022-12-01T09:55:59.494085Z","iopub.status.idle":"2022-12-01T09:55:59.621064Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"There are still some outliers in `Income`, but further observing other data for these customers (see first 7 datapoints in the table below), their `Education` and amounts spent on products do not contradict with their high level of income (e.g. they have high levels of education and have a high spending compared to other customers), so do not consider these as outliers and these datapoints are not removed.\n","metadata":{}},{"cell_type":"code","source":"customers %>% \n  arrange(desc(Income)) %>% \n  select(Education, Income, Age, HaveKids, DaysCustomer, Married,Recency, \n         Complain, MntWines, MntFruits, MntMeatProducts, MntFishProducts, \n         MntSweetProducts, MntGoldProds) %>% \n  head(10)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:56:29.091322Z","iopub.execute_input":"2022-12-01T09:56:29.097683Z","iopub.status.idle":"2022-12-01T09:56:29.201126Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.3 Attribute and regression matrices\nFirst, create matrices of attributes.","metadata":{}},{"cell_type":"code","source":"people_attrs <- customers[, c(\"Age\", \"Graduated\", \"Married\", \"Income\", \"HaveKids\",\n                              \"DaysCustomer\", \"Recency\", \"Complain\")]\nproduct_attrs <- customers[, c(\"MntWines\", \"MntFruits\", \"MntMeatProducts\", \n                               \"MntFishProducts\", \"MntSweetProducts\", \"MntGoldProds\")]\npromotion_attrs <- customers[, c(\"NumDealsPurchases\", \"AcceptedCmp1\", \"AcceptedCmp2\", \n                                 \"AcceptedCmp3\", \"AcceptedCmp4\", \"AcceptedCmp5\", \"Response\")]\nplace_attrs <- customers[, c(\"NumWebPurchases\", \"NumCatalogPurchases\", \"NumStorePurchases\")]","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:56:59.250698Z","iopub.execute_input":"2022-12-01T09:56:59.253256Z","iopub.status.idle":"2022-12-01T09:56:59.283893Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"attach(customers)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:57:49.703914Z","iopub.execute_input":"2022-12-01T09:57:49.705621Z","iopub.status.idle":"2022-12-01T09:57:49.728106Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Next, create dataframes for regression analysis. This project will be exploring 3 products with the following response variables:\n\n* Wine\n* Food (fish, meat and fruits combined)\n* Sweet products\n\nAlthough spending on gold products are included in the original dataset, this product type will not be explored as common supermarkets will probably not sell gold products.\n\nOur predictors will be all of the customer attributes. Hence, here 3 dataframes are created that contains one of the response variables (wine, food, or sweets) and all of the predictors.","metadata":{}},{"cell_type":"code","source":"# wine dataframe\ndf.wine <- cbind(MntWines, people_attrs)\n\n# Food dataframe\nMntFood <- MntFishProducts + MntMeatProducts + MntFruits\ndf.food <- cbind(MntFood, people_attrs)\n\n# Sweets dataframe\ndf.sweet <- cbind(MntSweetProducts, people_attrs)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:57:53.344568Z","iopub.execute_input":"2022-12-01T09:57:53.34623Z","iopub.status.idle":"2022-12-01T09:57:53.368774Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.4 Splitting into training and test set","metadata":{}},{"cell_type":"code","source":"# splitting dataframes into training set and test set\nset.seed(1)\n\n# wine\nwine.split <- initial_split(df.wine, prop=0.7, strata = MntWines)\nwine.train <- training(wine.split)\nwine.test <- testing(wine.split)\n\n# food\nfood.split <- initial_split(df.food, prop=0.7, strata = MntFood)\nfood.train <- training(food.split)\nfood.test <- testing(food.split)\n\n# sweets\nsweet.split <- initial_split(df.sweet, prop=0.7, strata = MntSweetProducts)\nsweet.train <- training(sweet.split)\nsweet.test <- testing(sweet.split)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:58:22.114939Z","iopub.execute_input":"2022-12-01T09:58:22.117799Z","iopub.status.idle":"2022-12-01T09:58:22.30989Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.5 Target & Feature engineering\n\nTarget & feature engineering include the following steps:\n\n* Log-transformed the outcome variables, which are spending on each product category (`MntWines` for wine, `MntFood` for food, and `MntSweetProducts` for sweets). Set `offset=1` since some spendings are 0 and will return `-Inf` if take log for that. \n* Dummy encoded all categorical vairables (such as `Graduated`, `Married`, `HaveKids`, etc.)\n* Centered and scaled all numerical vairables (except for outcome variables)\n\n**Target & Feature engineering for wine dataframe**\n","metadata":{}},{"cell_type":"code","source":"hist(MntWines)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:59:03.034734Z","iopub.execute_input":"2022-12-01T09:59:03.036288Z","iopub.status.idle":"2022-12-01T09:59:03.162605Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The amount spent on wine `MntWines` is skewed, so log transformation is necessary.","metadata":{}},{"cell_type":"code","source":"set.seed(1)\nwine.blueprint <- recipe(MntWines ~ ., data = wine.train) %>%\n  step_nzv(all_nominal())  %>%\n  step_impute_bag(Income) %>% \n  step_log(all_outcomes(), offset = 1) %>% # \n  step_dummy(all_nominal()) %>%\n  step_center(all_numeric(), -all_outcomes()) %>%\n  step_scale(all_numeric(), -all_outcomes())\nprepare.wine <- prep(wine.blueprint, training = wine.train)\nbaked.wine.train <- recipes::bake(prepare.wine, new_data = wine.train)\nbaked.wine.test <- recipes::bake(prepare.wine, new_data = wine.test)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:59:32.303494Z","iopub.execute_input":"2022-12-01T09:59:32.308848Z","iopub.status.idle":"2022-12-01T09:59:33.843531Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Retrieve the mean and standard deviation for `income` after imputation but before centering and scaling, as this will enable reverting the normalized income values back to the original scales.","metadata":{}},{"cell_type":"code","source":"set.seed(1)\nwine.income.impute <- recipe(MntWines ~ ., data = wine.train) %>%\n  step_impute_bag(Income) %>% \n  prep(training = wine.train, retain = TRUE) %>% \n  juice()\nincome.mean.wine <- mean(wine.income.impute$Income)\nincome.sd.wine <- sd(wine.income.impute$Income)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T09:59:51.867647Z","iopub.execute_input":"2022-12-01T09:59:51.870125Z","iopub.status.idle":"2022-12-01T09:59:52.733743Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Target & Feature engineering for food dataframe**","metadata":{}},{"cell_type":"code","source":"set.seed(1)\nfood.blueprint <- recipe(MntFood ~ ., data = food.train) %>%\n  step_nzv(all_nominal())  %>%\n  step_impute_bag(Income) %>% \n  step_log(all_outcomes(), offset = 1) %>% \n  step_dummy(all_nominal()) %>%\n  step_center(all_numeric(), -all_outcomes()) %>%\n  step_scale(all_numeric(), -all_outcomes())\nprepare.food <- prep(food.blueprint, training = food.train)\nbaked.food.train <- recipes::bake(prepare.food, new_data = food.train)\nbaked.food.test <- recipes::bake(prepare.food, new_data = food.test)\n\n# retrieving the mean and sd for income\nfood.income.impute <- recipe(MntFood ~ ., data = food.train) %>%\n  step_impute_bag(Income) %>% \n  prep(training = food.train, retain = TRUE) %>% \n  juice()\nincome.mean.food <- mean(food.income.impute$Income)\nincome.sd.food <- sd(food.income.impute$Income)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T10:00:13.020224Z","iopub.execute_input":"2022-12-01T10:00:13.026112Z","iopub.status.idle":"2022-12-01T10:00:14.921831Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Target & Feature engineering for sweets dataframe**","metadata":{}},{"cell_type":"code","source":"sweet.blueprint <- recipe(MntSweetProducts ~ ., data = sweet.train) %>%\n  step_nzv(all_nominal())  %>%\n  step_impute_bag(Income) %>% \n  step_log(all_outcomes(), offset = 1) %>% \n  step_dummy(all_nominal()) %>%\n  step_center(all_numeric(), -all_outcomes()) %>%\n  step_scale(all_numeric(), -all_outcomes())\nprepare.sweet <- prep(sweet.blueprint, training = sweet.train)\nbaked.sweet.train <- recipes::bake(prepare.sweet, new_data = sweet.train)\nbaked.sweet.test <- recipes::bake(prepare.sweet, new_data = sweet.test)\n\n# retrieving the mean and sd for income\nsweet.income.impute <- recipe(MntSweetProducts ~ ., data = sweet.train) %>%\n  step_impute_bag(Income) %>% \n  prep(training = sweet.train, retain = TRUE) %>% \n  juice()\nincome.mean.sweet <- mean(sweet.income.impute$Income)\nincome.sd.sweet <- sd(sweet.income.impute$Income)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T10:00:33.396755Z","iopub.execute_input":"2022-12-01T10:00:33.398391Z","iopub.status.idle":"2022-12-01T10:00:35.254512Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Method selection","metadata":{}},{"cell_type":"markdown","source":"Next, select a method to fit the final models. Workflow is as follows:\n\n* Implement a variety of methods (e.g. Xgboost/random forest/KNN) on only the wine dataframe, and record the training RMSE for each of the methods.\n* Based on the training RMSE, select the top models.\n* For each of these selected methods, fit the models on the test set, and select the one with the smallest test RMSE as the final model.\n* Fit the final model on the data to generate results, i.e. characteristics of customers that are likely to spend more on different product types.","metadata":{}},{"cell_type":"markdown","source":"## 3.1 Defining resampling method","metadata":{}},{"cell_type":"code","source":"cv <- trainControl(\n  method = \"repeatedcv\",\n  number = 10,\n  repeats = 5\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T10:04:28.055476Z","iopub.execute_input":"2022-12-01T10:04:28.058361Z","iopub.status.idle":"2022-12-01T10:04:28.079964Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.2 `Most Important` function\nCreate a function to store the most important features as a dataframe.","metadata":{}},{"cell_type":"code","source":"most_important <- function(vip) {\n  vip$data %>% \n  pull(Variable) %>% \n  as.data.frame()\n}","metadata":{"execution":{"iopub.status.busy":"2022-12-01T10:04:52.878922Z","iopub.execute_input":"2022-12-01T10:04:52.880851Z","iopub.status.idle":"2022-12-01T10:04:52.895369Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.3 Linear regression","metadata":{}},{"cell_type":"code","source":"wine.lm = train(\n  MntWines ~ .,\n  data = baked.wine.train,\n  trControl = cv,\n  method = \"glm\",\n  metric = \"RMSE\"\n)\n# storing RMSE on the training set\n(rmse.lm <- getTrainPerf(wine.lm)[[1]])","metadata":{"execution":{"iopub.status.busy":"2022-12-01T10:05:16.841689Z","iopub.execute_input":"2022-12-01T10:05:16.843176Z","iopub.status.idle":"2022-12-01T10:05:18.530823Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# storing the four most important features\nvip.lm <- most_important(vip(wine.lm))[1:4,]\n# variable importance plots\nvip(wine.lm)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T10:06:04.398341Z","iopub.execute_input":"2022-12-01T10:06:04.40093Z","iopub.status.idle":"2022-12-01T10:06:04.848094Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## 3.4 KNN","metadata":{"execution":{"iopub.status.busy":"2022-12-01T10:06:23.392912Z","iopub.execute_input":"2022-12-01T10:06:23.394563Z","iopub.status.idle":"2022-12-01T10:06:23.412175Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"set.seed(1)\n\n# hypergrid\nknn.hyper_grid <- expand.grid(k = seq(2, 26, by=2))\n\n# RMSE as preferred metric\nwine.knn <- train(\n  MntWines ~ .,\n  data = baked.wine.train,\n  method = \"knn\",\n  trControl = cv,\n  tuneGrid = knn.hyper_grid,\n  metric = \"RMSE\"\n)\n(rmse.knn <- getTrainPerf(wine.knn)[[1]])","metadata":{"execution":{"iopub.status.busy":"2022-12-01T10:06:32.58187Z","iopub.execute_input":"2022-12-01T10:06:32.587135Z","iopub.status.idle":"2022-12-01T10:06:39.086426Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.5 CART\nPerform CART and store the training RMSE.","metadata":{}},{"cell_type":"code","source":"set.seed(1)\nwine_dt1 <- train(\n  MntWines ~ .,\n  baked.wine.train,\n  method = \"rpart\",\n  trControl = cv,\n  tuneLength = 20\n)\n(rmse.cart <- getTrainPerf(wine_dt1)[[1]])","metadata":{"execution":{"iopub.status.busy":"2022-12-01T10:07:03.801241Z","iopub.execute_input":"2022-12-01T10:07:03.803875Z","iopub.status.idle":"2022-12-01T10:07:12.17891Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Re-perform CART with the best cp parameter from `wine_dt1`.","metadata":{}},{"cell_type":"code","source":"set.seed(1)\nwine_dt2 <- rpart(\n  MntWines ~ .,\n  data    = baked.wine.train,\n  method  = \"anova\",\n  control = list(cp = wine_dt1$bestTune[[1]], xval=10)\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T10:07:41.403679Z","iopub.execute_input":"2022-12-01T10:07:41.405384Z","iopub.status.idle":"2022-12-01T10:07:41.479854Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vip.cart <- most_important(vip(wine_dt2))[1:4,]\nvip(wine_dt2)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T10:07:48.227123Z","iopub.execute_input":"2022-12-01T10:07:48.231578Z","iopub.status.idle":"2022-12-01T10:07:48.759107Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.6 Random Forest","metadata":{}},{"cell_type":"code","source":"# number of features\nn_features <- length(setdiff(names(baked.wine.train), \"MntWines\"))","metadata":{"execution":{"iopub.status.busy":"2022-12-01T10:08:09.08735Z","iopub.execute_input":"2022-12-01T10:08:09.092752Z","iopub.status.idle":"2022-12-01T10:08:09.117545Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Perform the baseline Random Forest model.","metadata":{}},{"cell_type":"code","source":"# train a default random forest model\nwine_rf1 <- ranger(\n  MntWines ~ ., \n  data = baked.wine.train,\n  mtry = floor(n_features / 3),\n  respect.unordered.factors = \"order\",\n  seed = 123\n)\n\n# get OOB RMSE\n(rmse.rf.default <- sqrt(wine_rf1$prediction.error))","metadata":{"execution":{"iopub.status.busy":"2022-12-01T10:08:37.545004Z","iopub.execute_input":"2022-12-01T10:08:37.54669Z","iopub.status.idle":"2022-12-01T10:08:37.908917Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Next, tune hyperparameters for Random Forest.","metadata":{}},{"cell_type":"code","source":"# create hyperparameter grid\nrf.hyper_grid <- expand.grid(\n  mtry = floor(n_features * c(.05, .15, .25, .333, .4)),\n  min.node.size = c(1, 3, 5, 10), \n  replace = c(TRUE, FALSE),                               \n  sample.fraction = c(.5, .63, .8),                       \n  rmse = NA                                               \n)\n\n# execute full cartesian grid search\nfor(i in seq_len(nrow(rf.hyper_grid))) {\n  # fit model for ith hyperparameter combination\n  fit <- ranger(\n    formula         = MntWines ~ ., \n    data            = baked.wine.train, \n    num.trees       = n_features * 10,\n    mtry            = rf.hyper_grid$mtry[i],\n    min.node.size   = rf.hyper_grid$min.node.size[i],\n    replace         = rf.hyper_grid$replace[i],\n    sample.fraction = rf.hyper_grid$sample.fraction[i],\n    verbose         = FALSE,\n    seed            = 123,\n    respect.unordered.factors = 'order',\n  )\n  # export OOB error \n  rf.hyper_grid$rmse[i] <- sqrt(fit$prediction.error)\n}\n\n# save the best rmse\nrmse.rf.best <- min(rf.hyper_grid$rmse)\n\n# assess top 5 models\nrf.hyper_grid %>%\n  arrange(rmse) %>%\n  mutate(perc_gain = (rmse.rf.default - rmse) / rmse.rf.default * 100) %>%\n  head(5)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T10:09:00.984174Z","iopub.execute_input":"2022-12-01T10:09:00.985824Z","iopub.status.idle":"2022-12-01T10:09:06.328669Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Rerun the model with impurity-based and permutation-based importance measures.","metadata":{}},{"cell_type":"code","source":"# re-run model with impurity-based variable importance\nrf_impurity <- ranger(\n  formula = MntWines ~ ., \n  data = baked.wine.train, \n  num.trees = 2000,\n  mtry = 3,\n  min.node.size = 10,\n  sample.fraction = .63,\n  replace = FALSE,\n  importance = \"impurity\",\n  respect.unordered.factors = \"order\",\n  verbose = FALSE,\n  seed  = 123\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T10:09:25.829499Z","iopub.execute_input":"2022-12-01T10:09:25.831008Z","iopub.status.idle":"2022-12-01T10:09:27.10599Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# re-run model with permutation-based variable importance\nrf_permutation <- ranger(\n  formula = MntWines ~ ., \n  data = baked.wine.train, \n  num.trees = 2000,\n  mtry = 3,\n  min.node.size = 10,\n  sample.fraction = .63,\n  replace = FALSE,\n  importance = \"permutation\",\n  respect.unordered.factors = \"order\",\n  verbose = FALSE,\n  seed  = 123\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T10:09:33.576913Z","iopub.execute_input":"2022-12-01T10:09:33.582213Z","iopub.status.idle":"2022-12-01T10:09:36.283048Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Feature interpretation","metadata":{}},{"cell_type":"code","source":"rf.p1 <- vip(rf_impurity, bar = TRUE)\nrf.p2 <- vip(rf_permutation, bar = TRUE)\n\nvip.rf.impurity <- most_important(rf.p1)[1:4,]\nvip.rf.permutation <- most_important(rf.p2)[1:4,]\n\ngridExtra::grid.arrange(rf.p1, rf.p2, nrow = 1)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T10:09:47.202591Z","iopub.execute_input":"2022-12-01T10:09:47.205787Z","iopub.status.idle":"2022-12-01T10:09:47.810763Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.7 GBM","metadata":{}},{"cell_type":"code","source":"# run a basic GBM model\nset.seed(123) \nwine_gbm1 <- gbm(\n  formula = MntWines ~ .,\n  data = baked.wine.train,\n  distribution = \"gaussian\",  # SSE loss function\n  n.trees = 5000,\n  shrinkage = 0.1,\n  interaction.depth = 3,\n  n.minobsinnode = 10,\n  cv.folds = 10\n)\n\n# find index for number trees with minimum CV error\nbest <- which.min(wine_gbm1$cv.error)\n\n# get MSE and compute RMSE\n(rmse.basic.GBM <- sqrt(wine_gbm1$cv.error[best]))","metadata":{"execution":{"iopub.status.busy":"2022-12-01T10:10:19.312899Z","iopub.execute_input":"2022-12-01T10:10:19.31531Z","iopub.status.idle":"2022-12-01T10:10:44.920953Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Feature interpretation","metadata":{}},{"cell_type":"code","source":"vip.basic.gbm <- most_important(vip(wine_gbm1))[1:4,]\nvip(wine_gbm1)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T10:10:46.049992Z","iopub.execute_input":"2022-12-01T10:10:46.051799Z","iopub.status.idle":"2022-12-01T10:10:47.451868Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.8 Stochastic GBM","metadata":{}},{"cell_type":"code","source":"# initiate h2o session\nh2o.no_progress()\nh2o.init()\n\n# convert training data to h2o object\nwine.train_h2o <- as.h2o(baked.wine.train)\n\n# set the response column to Sale_Price\nresponse <- \"MntWines\"\n\n# set the predictor names\npredictors <- setdiff(colnames(baked.wine.train), response)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T10:11:19.694869Z","iopub.execute_input":"2022-12-01T10:11:19.696517Z","iopub.status.idle":"2022-12-01T10:11:28.968858Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Tune stochastic GBM hyperparameters.","metadata":{}},{"cell_type":"code","source":"# refined hyperparameter grid\nsto.gbm.hyper_grid <- list(\n  sample_rate = c(0.5, 0.75, 1),              # row subsampling\n  col_sample_rate = c(0.5, 0.75, 1),          # col subsampling for each split\n  col_sample_rate_per_tree = c(0.5, 0.75, 1)  # col subsampling for each tree\n)\n\n# random grid search strategy\nsearch_criteria <- list(\n  strategy = \"RandomDiscrete\",\n  stopping_metric = \"mse\",\n  stopping_tolerance = 0.001,\n  stopping_rounds = 10,\n  max_runtime_secs = 60*10\n)\n\n# perform grid search\ngrid <- h2o.grid(\n  algorithm = \"gbm\",\n  grid_id = \"gbm_grid\",\n  x = predictors,\n  y = response,\n  training_frame = wine.train_h2o,\n  hyper_params = sto.gbm.hyper_grid,\n  ntrees = 6000,\n  learn_rate = 0.01,\n  max_depth = 7,\n  min_rows = 5,\n  nfolds = 10,\n  stopping_rounds = 10,\n  stopping_tolerance = 0,\n  search_criteria = search_criteria,\n  seed = 123\n)\n\n# collect the results and sort by the model performance metric of choice\ngrid_perf <- h2o.getGrid(\n  grid_id = \"gbm_grid\",\n  sort_by = \"mse\",\n  decreasing = FALSE\n)\n\ngrid_perf","metadata":{"execution":{"iopub.status.busy":"2022-12-01T10:12:31.996901Z","iopub.execute_input":"2022-12-01T10:12:31.998494Z","iopub.status.idle":"2022-12-01T10:22:33.067981Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_model_id <- grid_perf@model_ids[[1]]\nbest_model <- h2o.getModel(best_model_id)\n\n# Now let’s get performance metrics on the best model\nh2o.performance(model = best_model, xval = TRUE)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T10:24:13.135138Z","iopub.execute_input":"2022-12-01T10:24:13.137217Z","iopub.status.idle":"2022-12-01T10:24:13.426434Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Saving and retrieving RMSE for stochastic GBM","metadata":{}},{"cell_type":"code","source":"(rmse.stochatic.gbm <- sqrt(grid_perf@summary_table[[5]][1]))","metadata":{"execution":{"iopub.status.busy":"2022-12-01T10:24:16.902093Z","iopub.execute_input":"2022-12-01T10:24:16.903767Z","iopub.status.idle":"2022-12-01T10:24:16.920797Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Feature interpretation","metadata":{}},{"cell_type":"code","source":"vip.stochastic.gbm <- most_important(vip(best_model))[1:4,]\nvip(best_model)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T10:24:26.53254Z","iopub.execute_input":"2022-12-01T10:24:26.534223Z","iopub.status.idle":"2022-12-01T10:24:26.76636Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.9 XGBoost\nAll categorical variables were already encoded numerically. Next, convert the training data frame to matrices","metadata":{}},{"cell_type":"code","source":"wine.X <- as.matrix(baked.wine.train[setdiff(names(baked.wine.train), \"MntWines\")])\nwine.Y <- baked.wine.train$MntWines","metadata":{"execution":{"iopub.status.busy":"2022-12-01T10:24:29.436574Z","iopub.execute_input":"2022-12-01T10:24:29.438107Z","iopub.status.idle":"2022-12-01T10:24:29.454004Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Perform grid search.","metadata":{}},{"cell_type":"code","source":"set.seed(1)\nwine_xgb <- xgb.cv(\n  data = wine.X,\n  label = wine.Y,\n  nrounds = 6000,\n  objective = \"reg:linear\",\n  early_stopping_rounds = 50, \n  nfold = 10,\n  params = list(\n    eta = 0.1,\n    max_depth = 3,\n    min_child_weight = 3,\n    subsample = 0.8,\n    colsample_bytree = 1.0),\n  verbose = 0\n)  ","metadata":{"execution":{"iopub.status.busy":"2022-12-01T10:24:31.68849Z","iopub.execute_input":"2022-12-01T10:24:31.690244Z","iopub.status.idle":"2022-12-01T10:24:32.722143Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# minimum test CV RMSE\n(rmse.xgb.baseline <- min(wine_xgb$evaluation_log$test_rmse_mean))","metadata":{"execution":{"iopub.status.busy":"2022-12-01T10:24:38.133276Z","iopub.execute_input":"2022-12-01T10:24:38.134888Z","iopub.status.idle":"2022-12-01T10:24:38.151321Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Next, perform a grid search that examines various regularization parameters","metadata":{}},{"cell_type":"code","source":"# the below code is commented out due to long processing time and warning messages, the results were shown in the next cell\n# wine.xbg.hyper_grid <- expand.grid(\n#   eta = 0.01,\n#   max_depth = 5, \n#   min_child_weight = 3,\n#   subsample = 0.5, \n#   colsample_bytree = 0.5,\n#   gamma = c(0, 1, 10, 100, 1000),\n#   lambda = c(0, 1e-2, 0.1, 1, 100),\n#   alpha = c(0, 1e-2, 0.1, 1, 100),\n#   rmse = 0,          # a place to dump RMSE results\n#   trees = 0          # a place to dump required number of trees\n# )\n\n# # grid search\n# for(i in seq_len(nrow(wine.xbg.hyper_grid))) {\n#   set.seed(1)\n#   m <- xgb.cv(\n#     data = wine.X,\n#     label = wine.Y,\n#     nrounds = 4000,\n#     objective = \"reg:linear\",\n#     early_stopping_rounds = 50, \n#     nfold = 10,\n#     verbose = FALSE,\n#     params = list( \n#       eta = wine.xbg.hyper_grid$eta[i], \n#       max_depth = wine.xbg.hyper_grid$max_depth[i],\n#       min_child_weight = wine.xbg.hyper_grid$min_child_weight[i],\n#       subsample = wine.xbg.hyper_grid$subsample[i],\n#       colsample_bytree = wine.xbg.hyper_grid$colsample_bytree[i],\n#       gamma = wine.xbg.hyper_grid$gamma[i], \n#       lambda = wine.xbg.hyper_grid$lambda[i], \n#       alpha = wine.xbg.hyper_grid$alpha[i]\n#     ) \n#   )\n#   wine.xbg.hyper_grid$rmse[i] <- min(m$evaluation_log$test_rmse_mean)\n#   wine.xbg.hyper_grid$trees[i] <- m$best_iteration\n# }\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-12-02T03:46:03.332036Z","iopub.execute_input":"2022-12-02T03:46:03.36821Z","iopub.status.idle":"2022-12-02T03:46:03.381909Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Grid search results:","metadata":{}},{"cell_type":"code","source":"# results\nrmse.xgb.best <- min(wine.xbg.hyper_grid$rmse)\n\nwine.xbg.hyper_grid %>%\n  filter(rmse > 0) %>%\n  arrange(rmse) %>%\n  glimpse()","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:11:59.021012Z","iopub.execute_input":"2022-12-01T11:11:59.022377Z","iopub.status.idle":"2022-12-01T11:11:59.082853Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.10 method comparison\n","metadata":{}},{"cell_type":"markdown","source":"Below is a table summarising the RMSE for training set for each method, in descending order.","metadata":{}},{"cell_type":"code","source":"reg.methods <- c(\"Basic GBM\", \"KNN\", \"LM\", \n                 \"CART\",\"RF\",\"RF (baseline)\", \n                 \"Stochastic GBM\",\n                 \"Xgboost\")\nreg.rmses <- c(rmse.basic.GBM, rmse.knn, rmse.lm, \n               rmse.cart,rmse.rf.best, rmse.rf.default, \n               rmse.stochatic.gbm,\n               rmse.xgb.best)\ndf.rmse <- data.frame(reg.methods, reg.rmses)\ndf.rmse %>% \n  arrange(reg.rmses)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:13:45.744514Z","iopub.execute_input":"2022-12-01T11:13:45.746232Z","iopub.status.idle":"2022-12-01T11:13:45.780441Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"From the above table, 3 models that have a lower RMSE are chosen:\n\n* `Xgboost` (chosen as a representation of the Gradient Boosting methods)\n* RF (Random Forest)\n* CART","metadata":{}},{"cell_type":"markdown","source":"# 4. Model and Regression Trees\n\n## 4.1 CART\nPlot the resulted tree from CART model `wine_dt2`.","metadata":{}},{"cell_type":"code","source":"rpart.plot(wine_dt2)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:13:57.133439Z","iopub.execute_input":"2022-12-01T11:13:57.135044Z","iopub.status.idle":"2022-12-01T11:13:57.697577Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"*Note: the outputted plot and the plot on which the below analysis below is based are different.*\n*The difference however does not result in difference in the next steps and conclusions.*","metadata":{}},{"cell_type":"markdown","source":"The node with the highest predicted value is the node on the far right with predicted `y = 6.4`. Following the branches from root node to this terminal node, the following characteristics are summarized:","metadata":{}},{"cell_type":"code","source":"print(paste(\"highest prediction:\", exp(6.4)))\nprint(paste(\"percentile:\", sum(customers$MntWines<exp(6.4))/length(customers$MntWines)))\nprint(paste(\"income >=:\", -0.33*income.sd.wine+income.mean.wine))\nprint(paste(\"income >:\", 0.15*income.sd.wine+income.mean.wine))\nprint(paste(\"income <:\", 2.6*income.sd.wine+income.mean.wine))\nprint(paste(\"income >=:\", 0.48*income.sd.wine+income.mean.wine))\nprint(paste(\"days customers >:\", 0.24*sd(customers$DaysCustomer)+mean(customers$DaysCustomer)))","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:14:02.570497Z","iopub.execute_input":"2022-12-01T11:14:02.572354Z","iopub.status.idle":"2022-12-01T11:14:02.609718Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Make predictions on the test set and save the resulted RMSE.","metadata":{}},{"cell_type":"code","source":"wine.cart.pred <- predict(wine_dt2, newdata = baked.wine.test[, -9])\n(test.rmse.wine.cart <- rmse(as.numeric(unlist(baked.wine.test[, 9])), wine.cart.pred))","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:14:04.794666Z","iopub.execute_input":"2022-12-01T11:14:04.79652Z","iopub.status.idle":"2022-12-01T11:14:04.820479Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.2 Xgboost\nRetrieve the list of optimal hyperparameters from above to train the final model.","metadata":{}},{"cell_type":"code","source":"wine.xgb.params <- list(\n  eta = 0.01,\n  max_depth = 5,\n  min_child_weight = 3,\n  subsample = 0.5,\n  colsample_bytree = 0.5,\n  gamma = 1,\n  alpha = 1,\n  lambda = 100\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:14:06.563232Z","iopub.execute_input":"2022-12-01T11:14:06.565108Z","iopub.status.idle":"2022-12-01T11:14:06.578451Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train final model\nset.seed(1)\nwine.xgb.fit.final <- xgboost::xgboost(\n  params = wine.xgb.params,\n  data = wine.X,\n  label = wine.Y,\n  nrounds = 1343,\n  objective = \"reg:squarederror\",\n  verbose = FALSE)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:14:19.683224Z","iopub.execute_input":"2022-12-01T11:14:19.684916Z","iopub.status.idle":"2022-12-01T11:14:21.457132Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gr <- xgb.plot.tree(model=wine.xgb.fit.final, trees=1342, render=FALSE)\nexport_graph(gr, 'tree.pdf', width=1500, height=1900)\nxgb.plot.tree(model = wine.xgb.fit.final, trees = 1342)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:14:21.459711Z","iopub.execute_input":"2022-12-01T11:14:21.461219Z","iopub.status.idle":"2022-12-01T11:14:25.700233Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"xgbtable <- xgb.model.dt.tree(model=wine.xgb.fit.final)\nxgbtable %>% \n  filter(Tree==1342 & Feature == \"Leaf\") %>% \n  arrange(desc(Quality))","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:14:25.703509Z","iopub.execute_input":"2022-12-01T11:14:25.705545Z","iopub.status.idle":"2022-12-01T11:14:26.109536Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The node that gives the highest prediction is node 8 (highest `quality` in the above table). Following the branches from root node to this terminal node, the following characteristics are summarized:","metadata":{}},{"cell_type":"code","source":"xgbtable %>% \n  filter(Tree==1342)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:14:26.111922Z","iopub.execute_input":"2022-12-01T11:14:26.113325Z","iopub.status.idle":"2022-12-01T11:14:26.149547Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(paste(\"(node 0->1) income <:\", 0.9065892*income.sd.wine+income.mean.wine))\nprint(paste(\"(node 1->3) income <:\", -0.7366908*sd(customers$Age)+mean(customers$Age)))\nprint(paste(\"(node 3->8) income >:\", -1.3820734*sd(customers$Recency)+mean(customers$Recency)))","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:14:26.152419Z","iopub.execute_input":"2022-12-01T11:14:26.15387Z","iopub.status.idle":"2022-12-01T11:14:26.17886Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"wine.xgb.pred <- predict(wine.xgb.fit.final, newdata = data.matrix(baked.wine.test[, -9]))\n(test.rmse.wine.xgb <- rmse(as.numeric(unlist(baked.wine.test[, 9])), wine.xgb.pred))","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:14:26.181134Z","iopub.execute_input":"2022-12-01T11:14:26.182489Z","iopub.status.idle":"2022-12-01T11:14:26.213657Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vip.xgb <- most_important(vip(wine.xgb.fit.final))[1:4,]\nvip(wine.xgb.fit.final)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:14:26.21604Z","iopub.execute_input":"2022-12-01T11:14:26.217523Z","iopub.status.idle":"2022-12-01T11:14:26.515715Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.3 Random Forest\nPlotting the tree using the tuned parameters found from the previous section.","metadata":{}},{"cell_type":"code","source":"set.seed(1)\nwine.cf <- party::cforest(MntWines ~ ., \n                          data=baked.wine.train, \n                          controls=cforest_control(mtry=3, \n                                                   mincriterion = 1,\n                                                   replace = FALSE, ntree = 2000, \n                                                   fraction = 0.63))\nwine.pt <- prettytree(wine.cf@ensemble[[1]], names(wine.cf@data@get(\"input\"))) \nwine.nt <- new(\"BinaryTree\") \nwine.nt@tree <- wine.pt \nwine.nt@data <- wine.cf@data \nwine.nt@responses <- wine.cf@responses\n\nplot(wine.nt, type=\"simple\")","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:14:26.518744Z","iopub.execute_input":"2022-12-01T11:14:26.520318Z","iopub.status.idle":"2022-12-01T11:14:37.529855Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"*Note: the outcome is slightly different from the one on which the following analysis is based*\n\nThe highest node is node 15 with predicted `y = 6.81`. Following the branches from root node to this terminal node, summarise the following characteristics are summarized:","metadata":{}},{"cell_type":"code","source":"print(paste(\"highest prediction:\", exp(6.81)))\nprint(paste(\"percentile:\", sum(customers$MntWines<exp(6.81))/length(customers$MntWines)))\nprint(paste(\"married <=:\", -1.352*sd(customers$HaveKids)+mean(customers$HaveKids)))\nprint(paste(\"days customers >:\", 0.936*sd(customers$DaysCustomer)+mean(customers$DaysCustomer)))\nprint(paste(\"income >=:\", 0.389*income.sd.wine+income.mean.wine))\nprint(paste(\"income >:\", -0.467*income.sd.wine+income.mean.wine))\nprint(paste(\"age >:\", -0.02*sd(customers$Age)+mean(customers$Age)))\nprint(paste(\"kids <=:\", -1.561*sd(customers$HaveKids)+mean(customers$HaveKids)))","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:14:37.533715Z","iopub.execute_input":"2022-12-01T11:14:37.536062Z","iopub.status.idle":"2022-12-01T11:14:37.584759Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Save the test error for Random Forest.","metadata":{}},{"cell_type":"code","source":"wine.rf.pred <- predict(rf_impurity, data=baked.wine.test[, -9], type=\"response\")\n(test.rmse.wine.rf <- rmse(as.numeric(unlist(baked.wine.test[, 9])), wine.rf.pred$predictions))","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:14:37.588083Z","iopub.execute_input":"2022-12-01T11:14:37.589736Z","iopub.status.idle":"2022-12-01T11:14:37.835485Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.4 Method comparison","metadata":{}},{"cell_type":"code","source":"test.methods <- c(\"Xgboost\", \"CART\", \"RF\")\ntest.rmses <- c(test.rmse.wine.xgb,test.rmse.wine.cart, test.rmse.wine.rf)\ndf.test.rmse <- data.frame(test.methods, test.rmses)\ndf.test.rmse %>% \n  arrange(test.rmses)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:14:37.838516Z","iopub.execute_input":"2022-12-01T11:14:37.839944Z","iopub.status.idle":"2022-12-01T11:14:37.871188Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Amongst the three methods, Random Forest has the lowest RMSE on the test set. On the merit of this, Random Forest is chosen to fit the final models.","metadata":{}},{"cell_type":"markdown","source":"# 5 Final model and predictions","metadata":{}},{"cell_type":"markdown","source":"## 5.1 Amount spent on wine (see above)","metadata":{}},{"cell_type":"code","source":"## 5.2 Amount spent on food (fish, meat, fruits)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:14:37.874694Z","iopub.execute_input":"2022-12-01T11:14:37.876394Z","iopub.status.idle":"2022-12-01T11:14:37.888885Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Tuning hyperparameters","metadata":{}},{"cell_type":"code","source":"# create hyperparameter grid\nfood.rf.hyper_grid <- expand.grid(\n  mtry = floor(n_features * c(.05, .15, .25, .333, .4)),\n  min.node.size = c(1, 3, 5, 10), \n  replace = c(TRUE, FALSE),                               \n  sample.fraction = c(.5, .63, .8),                       \n  rmse = NA                                               \n)\n\n# execute full cartesian grid search\nfor(i in seq_len(nrow(food.rf.hyper_grid))) {\n  # fit model for ith hyperparameter combination\n  fit <- ranger(\n    formula         = MntFood ~ ., \n    data            = baked.food.train, \n    num.trees       = n_features * 10,\n    mtry            = food.rf.hyper_grid$mtry[i],\n    min.node.size   = food.rf.hyper_grid$min.node.size[i],\n    replace         = food.rf.hyper_grid$replace[i],\n    sample.fraction = food.rf.hyper_grid$sample.fraction[i],\n    verbose         = FALSE,\n    seed            = 123,\n    respect.unordered.factors = 'order',\n  )\n  # export OOB error \n  food.rf.hyper_grid$rmse[i] <- sqrt(fit$prediction.error)\n}\n\n# assess top 5 models\nfood.rf.hyper_grid %>%\n  arrange(rmse) %>%\n  mutate(perc_gain = (rmse.rf.default - rmse) / rmse.rf.default * 100) %>%\n  head(5)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:14:37.892353Z","iopub.execute_input":"2022-12-01T11:14:37.894069Z","iopub.status.idle":"2022-12-01T11:14:42.112494Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Rerun models with best parameters and feature interpretation","metadata":{}},{"cell_type":"code","source":"# re-run model with impurity-based variable importance\nfood.rf_impurity <- ranger(\n  formula = MntFood ~ ., \n  data = baked.food.train, \n  num.trees = 2000,\n  mtry = 3,\n  min.node.size = 3,\n  sample.fraction = .50,\n  replace = FALSE,\n  importance = \"impurity\",\n  respect.unordered.factors = \"order\",\n  verbose = FALSE,\n  seed  = 123\n)\n\n# re-run model with permutation-based variable importance\nfood.rf_permutation <- ranger(\n  formula = MntFood ~ ., \n  data = baked.food.train, \n  num.trees = 2000,\n  mtry = 3,\n  min.node.size = 3,\n  sample.fraction = .50,\n  replace = FALSE,\n  importance = \"permutation\",\n  respect.unordered.factors = \"order\",\n  verbose = FALSE,\n  seed  = 123\n)\n\nfood.rf.p1 <- vip::vip(food.rf_impurity)\nfood.rf.p2 <- vip::vip(food.rf_permutation)\n\ngridExtra::grid.arrange(food.rf.p1, food.rf.p2, nrow = 1)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:14:42.114827Z","iopub.execute_input":"2022-12-01T11:14:42.116243Z","iopub.status.idle":"2022-12-01T11:14:46.123904Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"`Income`,  `HaveKids`, `DaysCustomer` and `Age` are the four most important features.\n\nPlotting the resulted tree:","metadata":{}},{"cell_type":"code","source":"# library(\"party\")\nset.seed(1)\nfood.cf <- party::cforest(MntFood ~ ., data=baked.food.train,\n                     controls=cforest_control(\n                       mtry=3, \n                       replace = FALSE, \n                       ntree = 2000, \n                       fraction = 0.5))\n\n\nfood.pt <- prettytree(food.cf@ensemble[[1]], names(food.cf@data@get(\"input\"))) \nfood.nt <- new(\"BinaryTree\") \nfood.nt@tree <- food.pt \nfood.nt@data <- food.cf@data \nfood.nt@responses <- food.cf@responses \n\nplot(food.nt, type=\"simple\")","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:14:46.126351Z","iopub.execute_input":"2022-12-01T11:14:46.128136Z","iopub.status.idle":"2022-12-01T11:14:54.287541Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The highest node is node 19 with predicted `y = 6.618`. Following the branches from root node to this terminal node, the following characteristics are summarized:","metadata":{}},{"cell_type":"code","source":"print(paste(\"highest prediction:\", exp(6.618)))\nprint(paste(\"percentile:\", sum(df.food$MntFood<exp(6.618))/length(df.food$MntFood)))\nprint(paste(\"age <=:\", 1.09*sd(customers$Age)+mean(customers$Age)))\nprint(paste(\"days customers >:\", -0.402*sd(customers$DaysCustomer)+mean(customers$DaysCustomer)))\nprint(paste(\"have kids <=:\", -1.611*sd(customers$HaveKids)+mean(customers$HaveKids)))\nprint(paste(\"age >:\", -1.013*sd(customers$Age)+mean(customers$Age)))\nprint(paste(\"income >:\", 0.261*income.sd.food+income.mean.food))","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:14:54.289986Z","iopub.execute_input":"2022-12-01T11:14:54.291435Z","iopub.status.idle":"2022-12-01T11:14:54.32623Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5.3 Amount spent on sweets\n\nTuning hyperparameters","metadata":{}},{"cell_type":"code","source":"# create hyperparameter grid\nsweet.rf.hyper_grid <- expand.grid(\n  mtry = floor(n_features * c(.05, .15, .25, .333, .4)),\n  min.node.size = c(1, 3, 5, 10), \n  replace = c(TRUE, FALSE),                               \n  sample.fraction = c(.5, .63, .8),                       \n  rmse = NA                                               \n)\n\n# execute full cartesian grid search\nfor(i in seq_len(nrow(sweet.rf.hyper_grid))) {\n  # fit model for ith hyperparameter combination\n  fit <- ranger(\n    formula         = MntSweetProducts ~ ., \n    data            = baked.sweet.train, \n    num.trees       = n_features * 10,\n    mtry            = sweet.rf.hyper_grid$mtry[i],\n    min.node.size   = sweet.rf.hyper_grid$min.node.size[i],\n    replace         = sweet.rf.hyper_grid$replace[i],\n    sample.fraction = sweet.rf.hyper_grid$sample.fraction[i],\n    verbose         = FALSE,\n    seed            = 123,\n    respect.unordered.factors = 'order',\n  )\n  # export OOB error \n  sweet.rf.hyper_grid$rmse[i] <- sqrt(fit$prediction.error)\n}\n\n# assess top 5 models\nsweet.rf.hyper_grid %>%\n  arrange(rmse) %>% \n  head(5)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:14:54.328601Z","iopub.execute_input":"2022-12-01T11:14:54.330019Z","iopub.status.idle":"2022-12-01T11:14:58.470549Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Rerun models with best parameters and feature interpretation","metadata":{}},{"cell_type":"code","source":"# re-run model with impurity-based variable importance\nsweet.rf_impurity <- ranger(\n  formula = MntSweetProducts ~ ., \n  data = baked.sweet.train, \n  num.trees = 2000,\n  mtry = 3,\n  min.node.size = 1,\n  sample.fraction = .63,\n  replace = TRUE,\n  importance = \"impurity\",\n  respect.unordered.factors = \"order\",\n  verbose = FALSE,\n  seed  = 123\n)\n\n# re-run model with permutation-based variable importance\nsweet.rf_permutation <- ranger(\n  formula = MntSweetProducts ~ ., \n  data = baked.sweet.train, \n  num.trees = 2000,\n  mtry = 3,\n  min.node.size = 1,\n  sample.fraction = .63,\n  replace = TRUE,\n  importance = \"permutation\",\n  respect.unordered.factors = \"order\",\n  verbose = FALSE,\n  seed  = 123\n)\n\nsweet.rf.p1 <- vip::vip(sweet.rf_impurity)\nsweet.rf.p2 <- vip::vip(sweet.rf_permutation)\n\ngridExtra::grid.arrange(sweet.rf.p1, sweet.rf.p2, nrow = 1)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:14:58.472925Z","iopub.execute_input":"2022-12-01T11:14:58.474302Z","iopub.status.idle":"2022-12-01T11:15:03.249669Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"`Income` is the most important feature; relative importance for other variables differ.\n\nPlotting the resulted tree","metadata":{}},{"cell_type":"code","source":"# library(\"party\")\nset.seed(1)\nsweet.cf <- party::cforest(MntSweetProducts ~ ., data=baked.sweet.train,\n                     controls=cforest_control(\n                       mtry=3, \n                       replace = TRUE, \n                       ntree = 2000, \n                       fraction = 0.63))\n\nsweet.pt <- prettytree(sweet.cf@ensemble[[1]], names(sweet.cf@data@get(\"input\"))) \nsweet.nt <- new(\"BinaryTree\") \nsweet.nt@tree <- sweet.pt \nsweet.nt@data <- sweet.cf@data \nsweet.nt@responses <- sweet.cf@responses \n\nplot(sweet.nt, type=\"simple\")","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:15:41.232105Z","iopub.execute_input":"2022-12-01T11:15:41.233764Z","iopub.status.idle":"2022-12-01T11:15:48.27507Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The highest node is node 22 with predicted `y = 4.281`. Following the branches from root node to this terminal node, the following characteristics are summarized:","metadata":{}},{"cell_type":"code","source":"print(paste(\"highest prediction:\", exp(4.281)))\nprint(paste(\"percentile:\", sum(df.sweet$MntSweetProducts<exp(4.281))/length(df.sweet$MntSweetProducts)))\nprint(paste(\"income >:\", 1.291*income.sd.sweet+income.mean.sweet))\nprint(paste(\"income >:\", 0.648*income.sd.sweet+income.mean.sweet))\nprint(paste(\"graduated >:\", -2.728*sd(customers$Graduated)+mean(customers$Graduated)))\nprint(paste(\"days customers <=:\", -0.978*sd(customers$DaysCustomer)+mean(customers$DaysCustomer)))","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:15:52.966935Z","iopub.execute_input":"2022-12-01T11:15:52.968549Z","iopub.status.idle":"2022-12-01T11:15:53.001313Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 6. Conclusion and insights\n","metadata":{}},{"cell_type":"markdown","source":"## 6.1 Feature importance","metadata":{}},{"cell_type":"code","source":"importance <- c(\"1st\", \"2nd\", \"3rd\", \"4th\")\ndf.vip <- data.frame(\n  importance,\n  vip.basic.gbm,\n  vip.cart,\n  vip.lm,\n  vip.rf.impurity,\n  vip.stochastic.gbm,\n  vip.xgb\n)\n\ndf.vip %>% \n  mutate_all(funs(str_replace(., \"DaysCustomer\", \"Days_Customer\")))","metadata":{"execution":{"iopub.status.busy":"2022-12-01T11:15:58.751607Z","iopub.execute_input":"2022-12-01T11:15:58.753299Z","iopub.status.idle":"2022-12-01T11:15:58.900608Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"It can be seen from the first and second rows of the above table that:\n\n* `Income` is always the most important variable in predicting spending\n* `DaysCustomer` (or `Days_Customer` used in presentation) is the next most important variable\n* other variables such as `Age`, `Recency` and `Graduated` also have some impacts","metadata":{}},{"cell_type":"markdown","source":"## 6.2 Recommendations actions\nBased on the above findings, it is recommended to target customers that are \n\n1. in the high income group (e.g. with an income higher than $57,000), and \n2. old customers (e.g. who have been registered with this supermarket for more than 270 days)\n\nThe supermarket may consider various marketing strategies including: \n1. Forming VIP clubs for high income groups; \n2. creating loyalty/rewards programmes for old customers; and \n3. send out offers for each product targeting specifically at the “ideal customer” identified for each product category.","metadata":{}}]}